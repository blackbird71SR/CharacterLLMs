{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOCK_SIZE = 3\n",
    "N_EMBED = 10\n",
    "N_HIDDEN = 64\n",
    "N_EPOCHS = 1000\n",
    "BATCH_SIZE = 32\n",
    "g = torch.Generator().manual_seed(2147483647)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createWordsMapping(filename = 'names.txt'):\n",
    "  words = open(filename, 'r').read().splitlines()\n",
    "  chars = sorted(list(set(''.join(words))))\n",
    "  stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "  stoi['.'] = 0\n",
    "  itos = {i:s for s,i in stoi.items()}\n",
    "  n_vocab = len(stoi)\n",
    "  return words, stoi, itos, n_vocab\n",
    "\n",
    "def buildDataset(words, block_size):\n",
    "  X, Y = [], []\n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix]\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  return X,Y\n",
    "\n",
    "def buildDatasets(words, block_size):\n",
    "  random.seed(42)\n",
    "  random.shuffle(words)\n",
    "  \n",
    "  n1 = int(0.8 * len(words))\n",
    "  n2 = int(0.9 * len(words))\n",
    "  \n",
    "  Xtr, Ytr = buildDataset(words[:n1], block_size)\n",
    "  Xdev, Ydev = buildDataset(words[n1:n2], block_size)\n",
    "  Xte, Yte = buildDataset(words[n2:], block_size)\n",
    "\n",
    "  return Xtr, Ytr, Xdev, Ydev, Xte, Yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, stoi, itos, n_vocab = createWordsMapping()\n",
    "Xtr, Ytr, Xdev, Ydev, Xte, Yte = buildDatasets(words, BLOCK_SIZE)\n",
    "n_embed, n_hidden, block_size, n_epochs, batch_size = N_EMBED, N_HIDDEN, BLOCK_SIZE, N_EPOCHS, BATCH_SIZE\n",
    "X, Y = Xtr, Ytr"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
